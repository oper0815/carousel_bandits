{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from functools import reduce\n",
    "from online_logistic_regression import OnlineLogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import ContextualEnvironment\n",
    "from policies import KLUCBSegmentPolicy, RandomPolicy, ExploreThenCommitSegmentPolicy, EpsilonGreedySegmentPolicy, TSSegmentPolicy, LinearTSPolicy\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--users_path\", type = str, default = \"data/user_features.csv\", required = False,\n",
    "                    help = \"Path to user features file\")\n",
    "parser.add_argument(\"--playlists_path\", type = str, default = \"data/playlist_features.csv\", required = False,\n",
    "                    help = \"Path to playlist features file\")\n",
    "parser.add_argument(\"--output_path\", type = str, default = \"results.json\", required = False,\n",
    "                    help = \"Path to json file to save regret values\")\n",
    "parser.add_argument(\"--policies\", type = str, default = \"random,ts-seg-naive\", required = False,\n",
    "                    help = \"Bandit algorithms to evaluate, separated by commas\")\n",
    "parser.add_argument(\"--n_recos\", type = int, default = 12, required = False,\n",
    "                    help = \"Number of slots L in the carousel i.e. number of recommendations to provide\")\n",
    "parser.add_argument(\"--l_init\", type = int, default = 3, required = False,\n",
    "                    help = \"Number of slots L_init initially visible in the carousel\")\n",
    "parser.add_argument(\"--n_users_per_round\", type = int, default = 20000, required = False,\n",
    "                    help = \"Number of users randomly selected (with replacement) per round\")\n",
    "parser.add_argument(\"--n_rounds\", type = int, default = 100, required = False,\n",
    "                    help = \"Number of simulated rounds\")\n",
    "parser.add_argument(\"--print_every\", type = int, default = 10, required = False,\n",
    "                    help = \"Print cumulative regrets every 'print_every' round\")\n",
    "\n",
    "args = parser.parse_args(args = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.read_csv('data/playlist_features.csv')\n",
    "\n",
    "users_df = pd.read_csv('data/user_features_small.csv')\n",
    "\n",
    "n_users = len(users_df)\n",
    "n_playlists = len(playlists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.array(users_df.drop([\"segment\"], axis = 1))\n",
    "user_features = np.concatenate([user_features, np.ones((n_users,1))], axis = 1)\n",
    "playlist_features = np.array(playlists_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_segment = np.array(users_df.segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_policies(policies_name, user_segment, user_features, n_playlists):\n",
    "    # Please see section 3.3 of RecSys paper for a description of policies\n",
    "    POLICIES_SETTINGS = {\n",
    "        'random' : RandomPolicy(n_playlists),\n",
    "        'etc-seg-explore' : ExploreThenCommitSegmentPolicy(user_segment, n_playlists, min_n = 100, cascade_model = True),\n",
    "        'etc-seg-exploit' : ExploreThenCommitSegmentPolicy(user_segment, n_playlists, min_n = 20, cascade_model = True),\n",
    "        'epsilon-greedy-explore' : EpsilonGreedySegmentPolicy(user_segment, n_playlists, epsilon = 0.1, cascade_model = True),\n",
    "        'epsilon-greedy-exploit' : EpsilonGreedySegmentPolicy(user_segment, n_playlists, epsilon = 0.01, cascade_model = True),\n",
    "        'kl-ucb-seg' : KLUCBSegmentPolicy(user_segment, n_playlists, cascade_model = True),\n",
    "        'ts-seg-naive' : TSSegmentPolicy(user_segment, n_playlists, alpha_zero = 1, beta_zero = 1, cascade_model = True),\n",
    "        'ts-seg-pessimistic' : TSSegmentPolicy(user_segment, n_playlists, alpha_zero = 1, beta_zero = 99, cascade_model = True),\n",
    "        'ts-lin-naive' : LinearTSPolicy(user_features, n_playlists, bias = 0.0, cascade_model = True),\n",
    "        'ts-lin-pessimistic' : LinearTSPolicy(user_features, n_playlists, bias = -5.0, cascade_model = True),\n",
    "        # Versions of epsilon-greedy-explore and ts-seg-pessimistic WITHOUT cascade model\n",
    "        'epsilon-greedy-explore-no-cascade' : EpsilonGreedySegmentPolicy(user_segment, n_playlists, epsilon = 0.1, cascade_model = False),\n",
    "        'ts-seg-pessimistic-no-cascade' : TSSegmentPolicy(user_segment, n_playlists, alpha_zero = 1, beta_zero = 99, cascade_model = False)\n",
    "    }\n",
    "\n",
    "    return [POLICIES_SETTINGS[name] for name in policies_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = 'random,ts-lin-pessimistic,ts-seg-pessimistic'\n",
    "policies_name = po.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init ========================================\n",
      "init ========================================\n"
     ]
    }
   ],
   "source": [
    "policies = set_policies(policies_name, user_segment, user_features, n_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random', 'ts-lin-pessimistic', 'ts-seg-pessimistic']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_policies = len(policies) # 3\n",
    "n_users_per_round = args.n_users_per_round\n",
    "n_rounds = args.n_rounds\n",
    "overall_rewards = np.zeros((n_policies, n_rounds))\n",
    "overall_optimal_reward = np.zeros(n_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_env = ContextualEnvironment(user_features, playlist_features, user_segment, args.n_recos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51069545, 0.60661954, 0.45462272, 0.35597582, 0.45974146,\n",
       "       0.33826388, 0.94396647, 0.6756706 , 0.35810638])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_env.th_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.random.choice(range(n_users), n_users_per_round) # range * 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10452.071280730333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(cont_env.th_rewards, user_ids).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 9\n",
    "u = 0\n",
    "step = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = np.take(user_features, range(0,9), axis = 0).dot(playlist_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = np.argsort(-probas)[:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "so1 = np.take(playlist_features, so, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_user_ids = range(0,9)\n",
    "batch_recos = so\n",
    "batch_user_features = np.take(user_features, batch_user_ids, axis = 0)              # batch 안에 있는 user에 대한 user_feature만 추출\n",
    "batch_playlist_features = np.take(playlist_features, batch_recos, axis = 0)    # 추천리스트에 있는 item에 대한 feature 추출\n",
    "n_users = len(batch_user_ids)                                                       # batch 내에 있는 유저 수\n",
    "th_reward = np.zeros(n_users)                                                       # zero vector 생성 (user 수)\n",
    "for i in range(n_users):                                                            # user 수 만큼 for 문 수행\n",
    "    probas = expit(batch_user_features[i].dot(batch_playlist_features[i].T)) \n",
    "    th_reward[i] = 1 - reduce(lambda x,y : x * y, 1 - probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.66080412, -2.93343552, -2.95593961, -3.30119431, -3.36031116,\n",
       "       -3.42852429, -3.46619029, -3.47532706, -3.49337995, -3.56729809,\n",
       "       -3.62311179, -3.65233738])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_user_features[i].dot(batch_playlist_features[i].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06532622, 0.05052526, 0.04945654, 0.03553024, 0.03355913,\n",
       "       0.03141581, 0.03028968, 0.03002246, 0.02950118, 0.02745687,\n",
       "       0.02600514, 0.02527506])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expit(batch_user_features[i].dot(batch_playlist_features[i].T)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):                                                            # user 수 만큼 for 문 수행\n",
    "    probas = expit(np.take(user_features, range(0,9), axis = 0)[i].dot(so1[i].T))        # sigmoid \n",
    "    th_reward[i] = 1 - reduce(lambda x,y : x * y, 1 - probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_rewards = np.zeros(user_features.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_rewards[0:9] = th_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_segment = np.array(users_df.segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_segments = len(np.unique(user_segment))                              # unique 한 segment 수\n",
    "segment_recos = np.zeros((n_segments, 12), dtype = np.int64)                 # (segment 수, 추천리스트 수) > segment 별로 동일한 추천리스트 생성\n",
    "for i in range(n_segments):\n",
    "    mean_probas = np.mean(expit(np.take(user_features, np.where(user_segment == i)[0], axis = 0).dot(playlist_features.T)), axis = 0)\n",
    "    reward = 1 - reduce(lambda x,y : x * y, 1 + np.sort(-mean_probas)[:12])\n",
    "    segment_recos[i] = np.argsort(-mean_probas)[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[195, 371,  51, 408, 128, 413, 251, 718, 396, 172, 178, 252]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_recos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ids = range(u, min(n_users, u + step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_segment = np.take(user_segment, users_ids)                    # batch 안에 있는 user의 segment 추출\n",
    "opt_recos = np.take(segment_recos, user_segment, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51069545, 0.60661954, 0.45462272, 0.35597582, 0.45974146,\n",
       "       0.33826388, 0.94396647, 0.6756706 , 0.35810638])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.random.choice(range(n_users), n_users_per_round)                                  # 전체 유저에서 batch 크기 만큼 샘플링 / 중복 유저도 가능한데...?\n",
    "overall_optimal_reward = np.take(cont_env.th_rewards, user_ids).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 4, ..., 1, 4, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n_policies):\n",
    "    # Compute n_recos recommendations\n",
    "    recos = policies[j].recommend_to_users_batch(user_ids, args.n_recos, args.l_init)\n",
    "    # Compute rewards\n",
    "    rewards = cont_env.simulate_batch_users_reward(batch_user_ids= user_ids, batch_recos=recos)\n",
    "    # Update policy based on rewards\n",
    "    policies[j].update_policy(user_ids, recos, rewards, args.l_init)\n",
    "    overall_rewards[j,i] = rewards.sum()\n",
    "# Print info\n",
    "if i == 0 or (i+1) % print_every == 0 or i+1 == n_rounds:\n",
    "    logger.info(\"Round: %d/%d. Elapsed time: %f sec.\" % (i+1, n_rounds, time.time() - start_time))\n",
    "    logger.info(\"Cumulative regrets: \\n%s \\n\" % \"\\n\".join([\"\t%s : %s\" % (policies_name[j], str(np.sum(overall_optimal_reward - overall_rewards[j]))) for j in range(n_policies)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 12)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies[0].recommend_to_users_batch(user_ids, args.n_recos, args.l_init).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __init__(self, user_features, n_playlists, bias=0.0, cascade_model=True):                       # LinearTSPolicy(user_features, n_playlists, bias = -5.0, cascade_model = True)\n",
    "    self.user_features = user_features\n",
    "    n_dim = user_features.shape[1]                                                                  # user feature dimension : 97\n",
    "    self.n_playlists = n_playlists                                                                  # item 수 : 862\n",
    "    self.models = [OnlineLogisticRegression(1, 1, n_dim, bias, 15) for i in range(n_playlists)]     # item\n",
    "    self.m = np.zeros((n_playlists, n_dim))                                                         # item feature matrix\n",
    "    self.m[:, -1] = bias\n",
    "    self.q = np.ones((n_playlists, n_dim))\n",
    "    self.n_dim = n_dim\n",
    "    self.cascade_model = cascade_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
